{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prosodic Feature-Based Behaviour Classification\n",
        "\n",
        "This notebook demonstrates the complete workflow from data loading to model evaluation and interpretability analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Add src to path\n",
        "sys.path.insert(0, str(Path('..') / 'src'))\n",
        "\n",
        "from utils.config import load_config\n",
        "from utils.logger import setup_logger\n",
        "from data_loader import load_ravdess, load_crema_d, load_savee\n",
        "from preprocessing import AudioPreprocessor\n",
        "from feature_extraction import ProsodicFeatureExtractor\n",
        "from models import ModelTrainer\n",
        "from evaluation import Evaluator\n",
        "from visualization import Plotter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = load_config('../configs/experiment.yaml')\n",
        "print(f\"Experiment: {config.experiment_name}\")\n",
        "print(f\"Datasets: {config.datasets}\")\n",
        "print(f\"Model: {config.model.model_type}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "datasets = []\n",
        "\n",
        "if 'ravdess' in config.datasets:\n",
        "    df_ravdess = load_ravdess(data_dir=f\"{config.data_dir}/ravdess\", download=True)\n",
        "    datasets.append(df_ravdess)\n",
        "\n",
        "if 'crema_d' in config.datasets:\n",
        "    df_crema = load_crema_d(data_dir=f\"{config.data_dir}/crema_d\", download=True)\n",
        "    datasets.append(df_crema)\n",
        "\n",
        "if 'savee' in config.datasets:\n",
        "    df_savee = load_savee(data_dir=f\"{config.data_dir}/savee\", download=True)\n",
        "    datasets.append(df_savee)\n",
        "\n",
        "# Combine datasets\n",
        "data_df = pd.concat(datasets, ignore_index=True)\n",
        "print(f\"Total samples: {len(data_df)}\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "print(data_df['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Extract Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize feature extractor\n",
        "extractor = ProsodicFeatureExtractor(\n",
        "    extract_prosodic=config.feature_extraction.extract_prosodic,\n",
        "    extract_spectral=config.feature_extraction.extract_spectral,\n",
        "    extract_mfcc=config.feature_extraction.extract_mfcc,\n",
        "    extract_formants=config.feature_extraction.extract_formants\n",
        ")\n",
        "\n",
        "# Extract features (using a subset for demonstration)\n",
        "sample_df = data_df.head(100)  # Use first 100 files for demo\n",
        "features_list = []\n",
        "\n",
        "for idx, row in sample_df.iterrows():\n",
        "    try:\n",
        "        features = extractor.extract_from_file(row['file_path'])\n",
        "        features['label'] = row['label']\n",
        "        features['speaker_id'] = row['speaker_id']\n",
        "        features_list.append(features)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {row['file_path']}: {e}\")\n",
        "\n",
        "features_df = pd.DataFrame(features_list)\n",
        "print(f\"Extracted features for {len(features_df)} files\")\n",
        "print(f\"Feature columns: {len([c for c in features_df.columns if c not in ['label', 'speaker_id', 'file_path']])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train and Evaluate Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize trainer\n",
        "trainer = ModelTrainer(\n",
        "    model_type=config.model.model_type,\n",
        "    hyperparameters=getattr(config.model, config.model.model_type, {}),\n",
        "    random_state=config.seed,\n",
        "    test_size=config.model.test_size,\n",
        "    cv_folds=config.model.cv_folds,\n",
        "    speaker_independent=config.model.speaker_independent\n",
        ")\n",
        "\n",
        "# Prepare data\n",
        "X, y, speaker_ids, feature_names = trainer.prepare_data(features_df)\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"Number of classes: {len(np.unique(y))}\")\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = trainer.split_data(X, y, speaker_ids)\n",
        "print(f\"Train set: {len(X_train)}, Test set: {len(X_test)}\")\n",
        "\n",
        "# Train model\n",
        "train_metrics = trainer.train(X_train, y_train)\n",
        "print(f\"\\nTraining metrics: {train_metrics}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_metrics = trainer.evaluate(X_test, y_test)\n",
        "print(f\"\\nTest Accuracy: {test_metrics['accuracy']:.4f}\")\n",
        "print(f\"Test F1 (Macro): {test_metrics['f1_macro']:.4f}\")\n",
        "print(f\"Test UAR: {test_metrics['uar']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Generate Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate visualizations\n",
        "evaluator = Evaluator(results_dir='../results')\n",
        "evaluator.plot_confusion_matrix(\n",
        "    y_test,\n",
        "    np.array(test_metrics['y_pred']),\n",
        "    trainer.label_encoder.classes_,\n",
        "    'notebook_analysis'\n",
        ")\n",
        "\n",
        "evaluator.plot_roc_curves(\n",
        "    y_test,\n",
        "    np.array(test_metrics['y_pred_proba']),\n",
        "    trainer.label_encoder.classes_,\n",
        "    'notebook_analysis'\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
